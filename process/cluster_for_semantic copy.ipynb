{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = '../data/WN18RR/'\n",
    "p2 = p1 + 'semantic/'\n",
    "R = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34033\t9500\n",
      "16102\t16109\n",
      "2466\t404\n",
      "707\t787\n",
      "3095\t7340\n",
      "2972\t309\n",
      "1978\t3990\n",
      "25\t594\n",
      "114\t873\n",
      "978\t980\n",
      "77\t76\n"
     ]
    }
   ],
   "source": [
    "r = [0]*R\n",
    "train = pd.read_csv(p1+'train2id.txt', sep=' ', header=0, names=[1,2,3])\n",
    "for i in range(R):\n",
    "    tmp1 = np.array(train[train[3]==i])\n",
    "    print(len(np.unique(tmp1[:,0])),end='\\t')\n",
    "    print(len(np.unique(tmp1[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = np.loadtxt(p2+'ent2semantic.txt', delimiter=' ')\n",
    "eww = np.loadtxt(p2+'entWithWords.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sem = (semantic - np.min(semantic)) / (np.max(semantic) - np.min(semantic))\n",
    "eid2sem = dict(zip(eww, sem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有关键字的实体\n",
    "ent_set = set(eww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(p1+'train2id.txt', sep=' ', header=0, names=[1,2,3])\n",
    "test = pd.read_csv(p1+'test2id.txt', sep=' ', header=0, names=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(x, k):\n",
    "    maxsc = 0\n",
    "    lb = []\n",
    "    for i in range(5):\n",
    "        tmp = KMeans(n_clusters=k).fit_predict(x)\n",
    "        sc = metrics.calinski_harabasz_score(x, tmp)\n",
    "        if maxsc < sc:\n",
    "            maxsc = sc\n",
    "            lb = tmp\n",
    "    return lb, maxsc\n",
    "\n",
    "def write_np(arr, p, sep=' '):\n",
    "    with open(p, 'w', encoding='utf-8') as f:\n",
    "        f.write(f'{len(arr)}\\n')\n",
    "        for i in arr:\n",
    "            line = ''\n",
    "            for j in i:\n",
    "                line += f'{int(j)}{sep}' \n",
    "            line = line.strip() + '\\n'\n",
    "            f.write(line)\n",
    "def normalize(arr):\n",
    "    arr = (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "对根据文本向量对头尾实体进行聚类，并记录结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros([1,5], dtype=int)\n",
    "tmp = train.copy(deep=True)\n",
    "tmp[4] = 0\n",
    "tmp[5] = 0\n",
    "k=10 # 聚类簇的个数\n",
    "\n",
    "box_num = np.zeros([R,2], dtype=int)\n",
    "start_idx = np.zeros([R,2], dtype=int)\n",
    "box_tot = np.zeros([2], dtype=int)\n",
    "nh = 0\n",
    "nt = 0\n",
    "\n",
    "for rid in range(R):\n",
    "    tmp1 = np.array(tmp[tmp[3] == rid])\n",
    "\n",
    "    km = KMeans(n_clusters=k, random_state=10)\n",
    "    \n",
    "    h = np.unique(tmp1[:,0])\n",
    "    t = np.unique(tmp1[:,1])\n",
    "    \n",
    "    if rid > 0:\n",
    "        start_idx[rid,0] = start_idx[rid-1,0] + hb\n",
    "        start_idx[rid,1] = start_idx[rid-1,1] + tb\n",
    "    \n",
    "    hb = 0\n",
    "    tb = 0\n",
    "    hpdic = {}\n",
    "    tpdic = {}\n",
    "    \n",
    "    flag = 1\n",
    "    tmp_eid = []\n",
    "    tmp_sem = np.zeros([128])\n",
    "    for i in h:\n",
    "        if i in ent_set:    # 判断是否具有文本信息\n",
    "            tmp_eid.append(i)\n",
    "            tmp_sem = np.vstack((tmp_sem, eid2sem.get(i)))\n",
    "        elif flag:\n",
    "            # 如果存在实体没有文本信息，那就为这类实体创建一个box\n",
    "            flag = 0\n",
    "            hb += 1\n",
    "    tmp_sem = np.delete(tmp_sem, 0, axis=0) # 删除第一行的全零\n",
    "    if len(tmp_eid) >= k:   # 如果带有文本信息的实体数量>=聚类簇数，则进行聚类\n",
    "        tmp_sem = normalize(tmp_sem)\n",
    "        try:\n",
    "            label, sc = func1(tmp_sem, k)   # label代表实体对应的boxid\n",
    "        except Exception:\n",
    "            label = km.fit_predict(tmp_sem)\n",
    "        if not flag:\n",
    "            label += 1\n",
    "        hpdic = dict(zip(tmp_eid, label))\n",
    "        hb += k\n",
    "    elif len(tmp_eid) > 0:\n",
    "        if not flag:\n",
    "            hpdic = dict(zip(tmp_eid, np.ones(len(tmp_eid), dtype=int)))\n",
    "        hb += 1\n",
    "    \n",
    "    flag = 1\n",
    "    tmp_eid = []\n",
    "    tmp_sem = np.zeros([128])\n",
    "    for i in t:\n",
    "        if i in ent_set:\n",
    "            tmp_eid.append(i)\n",
    "            tmp_sem = np.vstack((tmp_sem, eid2sem.get(i)))\n",
    "            # tmp_sem.append(eid2sem.get(i))\n",
    "        elif flag:\n",
    "            flag = 0\n",
    "            tb += 1\n",
    "    tmp_sem = np.delete(tmp_sem, 0, axis=0)\n",
    "    if len(tmp_eid) >= k:\n",
    "        tmp_sem = normalize(tmp_sem)\n",
    "        try:\n",
    "            label, sc = func1(tmp_sem, k)\n",
    "        except Exception:\n",
    "            label = km.fit_predict(tmp_sem)\n",
    "        if not flag:\n",
    "            label += 1\n",
    "        tpdic = dict(zip(tmp_eid, label))\n",
    "        tb += k\n",
    "    elif len(tmp_eid) > 0:\n",
    "        if not flag:\n",
    "            tpdic = dict(zip(tmp_eid, np.ones(len(tmp_eid), dtype=int)))\n",
    "        tb += 1\n",
    "    \n",
    "    box_num[rid, 0] = hb\n",
    "    box_num[rid, 1] = tb\n",
    "    box_tot[0] += hb\n",
    "    box_tot[1] += tb\n",
    "    \n",
    "    for i in range(len(tmp1)):\n",
    "        h = tmp1[i][0]\n",
    "        t = tmp1[i][1]\n",
    "\n",
    "        if hpdic.get(h): # 即使取到0也没关系，因为初值就是0，可以不修改\n",
    "            tmp1[i][3] = hpdic.get(h)\n",
    "        if tpdic.get(t):\n",
    "            tmp1[i][4] = tpdic.get(t)\n",
    "    res = np.concatenate([res, tmp1])\n",
    "res = np.delete(res, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86835, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = f'k{k}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_np(res, f'{p2}{version}train2id.txt')\n",
    "# np.savetxt(f'{p2}{version}train2id.txt', res,delimiter=' ', fmt='%d')\n",
    "np.savetxt(f'{p2}{version}box_num.txt', box_num, delimiter=' ', fmt='%d')\n",
    "np.savetxt(f'{p2}{version}box_tot.txt', box_tot, delimiter=' ', fmt='%d')\n",
    "np.savetxt(f'{p2}{version}start_idx.txt', start_idx, delimiter=' ', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3134, 5)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{p2}k{k}/train2id.txt', sep=' ', header=None, names=[1,2,3,4,5])\n",
    "tmp = test.copy(deep=True)\n",
    "tmp[4] = -1\n",
    "tmp[5] = -1\n",
    "res = np.zeros([1,5], dtype=int)\n",
    "for i in range(346):\n",
    "    # 根据rid选择triple\n",
    "    tmp1 = train[train[3] == i]\n",
    "    tmp2 = np.array(tmp[tmp[3] == i])\n",
    "#     print(f'{tmp1.shape}\\t{tmp2.shape}', end='\\t')\n",
    "    \n",
    "    # 获得头尾实体与具体box的对应关系\n",
    "    hdict = dict(zip(tmp1[1].values, tmp1[4].values))\n",
    "    tdict = dict(zip(tmp1[2].values, tmp1[5].values))\n",
    "    \n",
    "    for j in range(len(tmp2)):\n",
    "        h,t,r,hb,tb = tmp2[j]\n",
    "        if h in hdict.keys():\n",
    "            tmp2[j][3] = hdict.get(h)\n",
    "        \n",
    "        if t in tdict.keys():\n",
    "            tmp2[j][4] = tdict.get(t)\n",
    "    \n",
    "    res = np.concatenate([res, tmp2])\n",
    "res = np.delete(res, 0, axis=0)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_np(res, f'{p2}k{k}/test2id.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
